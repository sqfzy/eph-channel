import os
import sys
import subprocess
import json
import time
from pathlib import Path

# æ•°æ®å¤„ç†ä¸ç»˜å›¾
import polars as pl
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy import stats

# --- å…¨å±€é…ç½® ---
BASE_DIR = Path(__file__).resolve().parent.parent
BENCHMARK_DIR = BASE_DIR / "benchmark"
OUTPUT_DIR = BASE_DIR / "outputs"
BUILD_DIR = BASE_DIR / "build" / "linux" / "x86_64" / "release"

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
OUTPUT_DIR.mkdir(exist_ok=True)

# --- æ ¸å¿ƒè¾…åŠ©å‡½æ•° ---

def get_latest_file(pattern: str) -> Path | None:
    """æ ¹æ®æ¨¡å¼è·å–ç›®å½•ä¸‹æœ€æ–°çš„æ–‡ä»¶"""
    matches = list(OUTPUT_DIR.glob(pattern))
    if not matches:
        return None
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€åä¸€ä¸ª
    return max(matches, key=lambda p: p.stat().st_mtime)

def add_kde_trace(fig, data, row, col, color='purple', name='Density'):
    """è®¡ç®—å¹¶æ·»åŠ  KDE æ›²çº¿"""
    try:
        kde = stats.gaussian_kde(data)
        x_range = np.linspace(min(data), max(data), 500)
        y_kde = kde(x_range)
        fig.add_trace(
            go.Scatter(x=x_range, y=y_kde, mode='lines', name=name, line=dict(color=color, width=2)),
            row=row, col=col
        )
    except Exception as e:
        print(f"   [!] KDE è®¡ç®—ç•¥è¿‡: {e}")

# --- æŠ¥å‘Šç”Ÿæˆé€»è¾‘ ---

def generate_report(name: str):
    """åŠ¨æ€å®šä½æœ€æ–°çš„ CSV å¹¶ç”Ÿæˆ Plotly HTML æŠ¥å‘Š"""
    # é€‚é…æ–‡ä»¶åæ ¼å¼: bench_{name}*.csv
    csv_path = get_latest_file(f"bench_{name}*.csv")
    
    if not csv_path:
        # å…œåº•å°è¯•æŸ¥æ‰¾ç®€å•å‘½åçš„æ–‡ä»¶
        csv_path = OUTPUT_DIR / f"{name}.csv"
        if not csv_path.exists():
            print(f"   [è·³è¿‡] æœªæ‰¾åˆ°å¯¹åº”çš„ CSV æ•°æ®æ–‡ä»¶")
            return

    output_html = OUTPUT_DIR / f"{name}_latency_report.html"
    print(f"   [æŠ¥å‘Š] æ­£åœ¨åˆ†ææœ€æ–°æ•°æ®: {csv_path.name}")
    
    # 1. æ•°æ®åŠ è½½
    df = pl.read_csv(csv_path)
    # 2. P99 è¿‡æ»¤ç¦»ç¾¤ç‚¹
    upper_bound = df["latency_ns"].quantile(0.99)
    df_clean = df.filter(pl.col("latency_ns") <= upper_bound)

    # 3. åˆ›å»ºå­å›¾å¸ƒå±€
    fig = make_subplots(
        rows=3, cols=1,
        subplot_titles=(
            f"Time Series (Full Range)", 
            "Latency Distribution (Log Scale)", 
            "P99 Body Distribution (Linear + KDE)"
        ),
        vertical_spacing=0.1
    )

    # å›¾è¡¨ 1: Time Series
    fig.add_trace(
        go.Scatter(x=df["seq"], y=df["latency_ns"], mode='lines', name='Latency', line=dict(width=1, color='#1f77b4')),
        row=1, col=1
    )

    # å›¾è¡¨ 2: Log Distribution
    fig.add_trace(
        go.Histogram(x=df["latency_ns"], nbinsx=1000, name='Full Log', marker_color='#636EFA'),
        row=2, col=1
    )
    fig.update_yaxes(type="log", row=2, col=1)

    # å›¾è¡¨ 3: Linear Body + KDE
    fig.add_trace(
        go.Histogram(
            x=df_clean["latency_ns"], nbinsx=500, 
            name='Body', marker_color='#00CC96', opacity=0.6,
            histnorm='probability density'
        ),
        row=3, col=1
    )
    add_kde_trace(fig, df_clean["latency_ns"].to_numpy(), row=3, col=1)
    
    mean_val = df_clean["latency_ns"].mean()
    fig.add_vline(x=mean_val, line_dash="dash", line_color="red", row=3, col=1)

    # å¸ƒå±€å¾®è°ƒ
    fig.update_layout(
        # height=1000, 
        title_text=f"Benchmark Comprehensive Report: {name}<br><sup>Source: {csv_path.name}</sup>",
        showlegend=False, 
        template="plotly_white"
    )
    
    fig.write_html(str(output_html))
    print(f"   [æŠ¥å‘Š] HTML å·²ä¿å­˜: {output_html.name}")

# --- ä»»åŠ¡æ‰§è¡Œé€»è¾‘ ---

def run_single_bench(name: str):
    target_bin = f"benchmark_{name}"
    exec_path = BUILD_DIR / target_bin
    needs_roudi = ("iox" in name) # æ›´åŠ é€šç”¨çš„åˆ¤æ–­

    print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œæµ‹è¯•ç›®æ ‡: {name}")

    # A. ç¼–è¯‘ (xmake)
    print(f"   [1/3] æ„å»ºä¸­...")
    if subprocess.run(["xmake", "build", target_bin], cwd=BASE_DIR, capture_output=True).returncode != 0:
        print(f"   âŒ æ„å»ºå¤±è´¥: {target_bin}")
        return

    # B. è¿è¡Œ (è€ƒè™‘ RouDi ç¯å¢ƒ)
    roudi_proc = None
    try:
        if needs_roudi:
            print("   [2/3] å¯åŠ¨ iox-roudi ç¯å¢ƒ...")
            f_log = open(BASE_DIR / "roudi.log", "w")
            roudi_proc = subprocess.Popen(["sudo", "iox-roudi"], stdout=f_log, stderr=subprocess.STDOUT)
            time.sleep(1.5)

        print("   [3/3] è¿è¡Œæµ‹è¯•äºŒè¿›åˆ¶ç¨‹åº...")
        subprocess.run(["sudo", str(exec_path)], check=True, cwd=BASE_DIR)
    except Exception as e:
        print(f"   âŒ è¿è¡Œæ—¶å‡ºé”™: {e}")
    finally:
        if roudi_proc:
            print("   [æ¸…ç†] æ­£åœ¨å…³é—­ iox-roudi...")
            subprocess.run(["sudo", "pkill", "-x", "iox-roudi"], check=False)
            roudi_proc.terminate()

    # C. è‡ªåŠ¨åˆ†ææœ€æ–°ç”Ÿæˆçš„ CSV
    generate_report(name)

def main():
    # è·å–ç›®å½•ä¸‹çš„å…¨éƒ¨å¯é€‰é¡¹
    cpp_files = (BENCHMARK_DIR / "examples").glob("*.cpp")
    available_targets = [f.stem for f in cpp_files]

    print("ğŸ“‹ å¯ç”¨æµ‹è¯•ç›®æ ‡:")
    for t in available_targets:
        print(f"   - {t}")
    
    user_args = sys.argv[1:]
    run_list = user_args if user_args else available_targets

    # éªŒè¯è¾“å…¥
    for t in run_list:
        if t not in available_targets:
            print(f"âŒ æ‰¾ä¸åˆ°ç›®æ ‡: {t}\nå¯é€‰ç›®æ ‡: {available_targets}")
            sys.exit(1)

    # ææƒä¸€æ¬¡ sudo
    subprocess.run(["sudo", "-v"], check=True)

    for target in run_list:
        run_single_bench(target)

    # æ±‡æ€»å±•ç¤º
    print("\n" + "="*50)
    print("ğŸ“Š æœ€ç»ˆçŠ¶æ€æ±‡æ€»")
    summary = []
    for t in run_list:
        json_file = get_latest_file(f"bench_{t}*.json")
        summary.append({
            "Target": t,
            "Status": "âœ…" if json_file else "âŒ",
            "Latest_Data": json_file.name if json_file else "N/A"
        })
    print(pl.DataFrame(summary))
    print("="*50)

if __name__ == "__main__":
    main()
